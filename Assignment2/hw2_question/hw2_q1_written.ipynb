{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AUwbFEaMiWi"
   },
   "source": [
    "# COMP3314 - Assignment 2\n",
    "\n",
    "## Question 1: Written Questions (10 Points, 2 points each) \n",
    "\n",
    "No need to implement any code. Please fill your answers in the following table. \n",
    "\n",
    "|   Q1   |  Q2   |   Q3   |  Q4   |   Q5   |  \n",
    "|  ----  | ----  |  ----  | ----  |  ----  | \n",
    "|    B   |   A   |  C    |  B    |   C    |  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6_-anGK53ee"
   },
   "source": [
    "### Q1\n",
    "\n",
    "If your AdaBoost ensemble underfits the training data, which hyperparameters should you tweak and how?\n",
    "\n",
    "A. Decreasing the number of estimators.\n",
    "\n",
    "B. Reducing the regularization hyperparameters of the base estimator.\n",
    "\n",
    "C. Decreasing the learning rate.\n",
    "\n",
    "D. None of above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsIKbwXx6f6m"
   },
   "source": [
    "### Q2\n",
    "\n",
    "For K-fold cross-validation, if we have a small training set, empirically, how to choose a K?\n",
    "\n",
    "A. A big value\n",
    "\n",
    "B. A small value\n",
    "\n",
    "C. Does not relavant to numbers of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5YVqiMV6ml2"
   },
   "source": [
    "### Q3\n",
    "\n",
    "What is the difference between hard and soft voting classifiers?\n",
    "\n",
    "A. Hard voting does not tolerant outliers for the training data.\n",
    "\n",
    "B. A soft voting classifier counts the votes of each classifier in the ensemble and picks the class that gets the most votes.\n",
    "\n",
    "C. A soft voting classifier works only if every classifier is able to estimate class probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXjEEjNl77T8"
   },
   "source": [
    "### Q4\n",
    "\n",
    "Once a dataset's dimensionality has been reduced from 1000 to 500 using PCA, normally, is it possible to reverse the operation without information loss? \n",
    "\n",
    "A. Yes.\n",
    "\n",
    "B. No."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXfwg4OC8_mQ"
   },
   "source": [
    "### Q5\n",
    "\n",
    "Suppose you perform PCA on a 1,000-dimensional dataset, setting the explained variance ratio to 95%. How many dimensions will the resulting dataset have?\n",
    "\n",
    "A. Around 50.\n",
    "\n",
    "B. Around 950.\n",
    "\n",
    "C. From 1-1000, depends on data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
